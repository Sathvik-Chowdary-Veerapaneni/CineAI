{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Checking MPS availability for Apple Silicon GPU acceleration\n",
    "mps_available = torch.backends.mps.is_built() and torch.backends.mps.is_available()\n",
    "device = \"mps\" if mps_available else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "dataset_url = \"SathvikVeerapaneni7/CineAI_Dataset\"\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in the dataset repository\n",
    "files = api.list_repo_files(repo_id=dataset_url, repo_type=\"dataset\")\n",
    "print(f\"Files in the Hugging Face dataset '{dataset_url}':\")\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# sample Loading a single Parquet file\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\"train\": \"https://huggingface.co/datasets/SathvikVeerapaneni7/CineAI_Dataset/resolve/main/parquet_files/details_df_clean.parquet\"},\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for processing if needed\n",
    "import pandas as pd\n",
    "details_df = pd.DataFrame(dataset)\n",
    "print(\"Loaded details_df from HF:\", details_df.shape)\n",
    "details_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Retrieval Pipeline Overview\n",
    "\n",
    "Our goal is to build a Retrieval-Augmented Generation (RAG) component that allows quick, semantic-level access to movie data.  \n",
    "We expect the outcome to be a system that, given a natural language query, retrieves relevant movie entries with thematic and narrative similarity.  \n",
    "\n",
    "\n",
    "Embed textual fields like `title`, `overview`, and optionally `genres` because they contain rich narrative and thematic information.  \n",
    "\n",
    "Not embedding purely numeric fields like `runtime` or `popularity` since they do not add semantic context. \n",
    "\n",
    "The final outcome should be a searchable index enabling users to discover related movies by concept rather than keyword.  \n",
    "This improves upon keyword search by returning results semantically aligned with the userâ€™s intent.  \n",
    "\n",
    "\n",
    "Limitations include potential model bias if overviews are sparse or genres are missing.  \n",
    "High-level concepts are captured, but rare details may be overlooked.  \n",
    "\n",
    "\n",
    "Future improvements can involve more diverse embeddings or integrating metadata filters.  \n",
    "\n",
    "\n",
    "Overall, this pipeline lays the foundation for robust semantic retrieval within the CineAI ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_data_files = {\"train\": f\"https://huggingface.co/datasets/{dataset_url}/resolve/main/parquet_files/details_df_clean.parquet\"}\n",
    "details_dataset = load_dataset(\"parquet\", data_files=details_data_files, split='train')\n",
    "details_df = pd.DataFrame(details_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_data_files = {\"train\": f\"https://huggingface.co/datasets/{dataset_url}/resolve/main/parquet_files/cast_df_clean.parquet\"}\n",
    "cast_df_dataset = load_dataset(\"parquet\", data_files=details_data_files, split='train')\n",
    "cast_df = pd.DataFrame(cast_df_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "details_data_files = {\"train\": f\"https://huggingface.co/datasets/{dataset_url}/resolve/main/parquet_files/crew_df_clean.parquet\"}\n",
    "crew_dataset= load_dataset(\"parquet\", data_files=details_data_files, split='train')\n",
    "crew_df = pd.DataFrame(crew_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_data_files = {\"train\": f\"https://huggingface.co/datasets/{dataset_url}/resolve/main/parquet_files/recommendations_df_clean.parquet\"}\n",
    "recommendations_dataset= load_dataset(\"parquet\", data_files=details_data_files, split='train')\n",
    "recommendations_df = pd.DataFrame(recommendations_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_data_files = {\"train\": f\"https://huggingface.co/datasets/{dataset_url}/resolve/main/parquet_files/watch_providers_df_clean.parquet\"}\n",
    "watch_providers_dataset= load_dataset(\"parquet\", data_files=details_data_files, split='train')\n",
    "watch_providers_df= pd.DataFrame(watch_providers_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes=[details_df,cast_df,crew_df,recommendations_df,watch_providers_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataframes:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"DataFrame {i+1} Columns:\")\n",
    "    print(df.columns)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: If 'text_for_embedding' doesn't exist, create it from 'title' and 'overview'.\n",
    "# We will combine them as a fallback.\n",
    "if 'text_for_embedding' not in details_df.columns:\n",
    "    details_df['text_for_embedding'] = details_df['title'].fillna('') + ' ' + details_df['overview'].fillna('')\n",
    "\n",
    "# Now concatenate genres_str if available\n",
    "if 'genres_str' in details_df.columns:\n",
    "    details_df['final_text'] = details_df['text_for_embedding'] + ' ' + details_df['genres_str'].fillna('')\n",
    "else:\n",
    "    details_df['final_text'] = details_df['text_for_embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Initialize the embedding model\n",
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_df['final_text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Comput embeddings\n",
    "embeddings = model.encode(details_df['final_text'].tolist(), convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB a Vector Database, to store the embeddgins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a client with the new recommended configuration.\n",
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        persist_directory=\"~/Desktop/CineAI/CineAI/chroma_db\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to the ChromaDB persist directory: /Users/HVMS/Desktop/CineAI/CineAI/src/embeddings/chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the full path to the persist directory\n",
    "full_path = os.path.join(current_directory, \"chroma_db\")\n",
    "\n",
    "# Print the full path\n",
    "print(\"Full path to the ChromaDB persist directory:\", full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=movies_new), Collection(name=movies)]\n"
     ]
    }
   ],
   "source": [
    "collections = client.list_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /Users/HVMS/Desktop/CineAI/CineAI/chroma_db: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -la ~/Desktop/CineAI/CineAI/chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Create or get the collection\n",
    "collection = client.get_or_create_collection(name=\"movies\")\n",
    "# Cell 2: Create or get the collection\n",
    "collection = client.get_or_create_collection(name=\"movies_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Remove duplicate movie_ids\n",
    "details_df = details_df.drop_duplicates(subset='movie_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Define a function to chunk the data\n",
    "def chunk_data(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i+chunk_size]\n",
    "\n",
    "# We'll create batches for ids, documents, and embeddings\n",
    "ids = details_df['movie_id'].astype(str).tolist()\n",
    "docs = details_df['text_for_embedding'].tolist()\n",
    "embs = embeddings.tolist()\n",
    "\n",
    "# According to the error, max batch size is 41666\n",
    "max_batch_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Add documents in chunks\n",
    "for id_chunk, doc_chunk, emb_chunk in zip(\n",
    "    chunk_data(ids, max_batch_size),\n",
    "    chunk_data(docs, max_batch_size),\n",
    "    chunk_data(embs, max_batch_size)\n",
    "):\n",
    "    collection.add(\n",
    "        documents=doc_chunk,\n",
    "        ids=id_chunk,\n",
    "        embeddings=emb_chunk\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sample semantic query\n",
    "query_text = \"What is the actor real name in iron man movie \"\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Testing, with random data , to verify logs and embedding storgare in paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Client, Settings\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Adjust the directory name slightly to avoid conflict\n",
    "    client = Client(\n",
    "        Settings(\n",
    "            persist_directory=(\"/Users/HVMS/Desktop/CineAI/CineAI/src/embeddings\", \"sample_embeddings_new\")\n",
    "        )\n",
    "    )\n",
    "    logging.debug(\"Initialized new ChromaDB client with a new directory: %s\", os.path.join(os.getcwd(), \"sample_embeddings_new\"))\n",
    "except ValueError as e:\n",
    "    logging.error(\"Failed to initialize ChromaDB client: %s\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CineAI MPS Env",
   "language": "python",
   "name": "cineai_mps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
